# Big O, Big Theta and Big Omega

Big O: gives upper bound
Big Omega: gives lower bound
Big Theta: gives tight bound

if Big O and Big Omega are same, then it is Big Theta

### What is Big Theta (Î˜) Notation?

**Big Theta (Î˜)** is used in **asymptotic analysis** to describe the **tight bound** on the runtime (or space) of an algorithm. It tells us that the algorithm grows at **exactly** that rate (within constant factors), both from above and below, for sufficiently large inputs.

---

### In Simple Terms:

If a function \( f(n) \) is **Î˜(g(n))**, it means:

> For large enough \( n \), \( f(n) \) grows at the **same rate** as \( g(n) \), up to constant multipliers.

---

### Formal Definition:

We say  
\[
f(n) \in \Theta(g(n))
\]  
if there exist **constants** \( c_1, c_2 > 0 \) and \( n_0 \) such that:

\[
c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n) \quad \text{for all } n \geq n_0
\]

So it's a **sandwich**:  
The function \( f(n) \) is **bounded above and below** by \( g(n) \), multiplied by some constants.

---

### Example:

Letâ€™s say:
\[
f(n) = 3n^2 + 2n + 5
\]

We can say:
\[
f(n) \in \Theta(n^2)
\]

Because:

- The dominant term is \( 3n^2 \)
- Lower-order terms (\( 2n + 5 \)) become negligible as \( n \) grows
- So \( f(n) \) is **tightly bound** to \( n^2 \)

---

### Comparison with Big O and Big Omega:

| Notation    | Meaning     | Bound          |
| ----------- | ----------- | -------------- |
| **O(g(n))** | Upper bound | Worst case (â‰¤) |
| **Î©(g(n))** | Lower bound | Best case (â‰¥)  |
| **Î˜(g(n))** | Tight bound | Both O and Î©   |

If \( f(n) \in \Theta(g(n)) \), then:
\[
f(n) \in O(g(n)) \quad \text{and} \quad f(n) \in \Omega(g(n))
\]

---

### ğŸ“¦ Real-World Analogy:

Imagine a highway:

- **O(g(n))**: â€œIt takes at **most** this much time to drive.â€
- **Î©(g(n))**: â€œIt takes at **least** this much time.â€
- **Î˜(g(n))**: â€œIt consistently takes this amount of time â€” within a small wiggle room.â€

### Difference between Big O and Big Theta

Comes down to **how tightly** they describe the growth of a function.

---

### TL;DR:

| Notation          | Describes   | Type of Bound | Analogy                            |
| ----------------- | ----------- | ------------- | ---------------------------------- |
| **Big O** (O)     | Upper Bound | "At most"     | Max time it might take             |
| **Big Theta** (Î˜) | Tight Bound | "Exactly"     | Average time it consistently takes |

---

### ğŸ” In Detail:

#### **Big O â€” Upper Bound**

- Says: â€œThe function grows **no faster than** this.â€
- It gives a **ceiling**.
- **Used for**: Worst-case analysis.

\[
f(n) \in O(g(n)) \Rightarrow f(n) \leq c \cdot g(n) \text{ for large } n
\]

Example:

```text
If an algorithm runs in f(n) = 3n + 2 time,
then f(n) âˆˆ O(n) â€” because it wonâ€™t grow faster than linear.
```

---

#### **Big Theta â€” Tight Bound**

- Says: â€œThe function grows at **exactly this rate**, within constants.â€
- It gives a **floor and a ceiling**.
- **Used for**: Precise algorithm growth.

\[
f(n) \in \Theta(g(n)) \Rightarrow c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n) \text{ for large } n
\]

ğŸ“Œ Example:

```text
If f(n) = 3n + 2, then f(n) âˆˆ Î˜(n) â€” because it grows linearly from both above and below.
```

---

### Metaphor Time:

Imagine describing someoneâ€™s height:

- **Big O**: â€œHeâ€™s no taller than 6'0".â€ (Maybe shorter!)
- **Big Î˜**: â€œHeâ€™s between 5'11" and 6'1" â€” so yeah, basically 6'0".â€

Big O gives a **limit**, Theta gives a **tight fit**.

---

### Codey Example:

```python
def count_pairs(arr):
    count = 0
    for i in range(len(arr)):
        for j in range(i+1, len(arr)):
            count += 1
    return count
```

- **Time complexity**: \( f(n) = \frac{n(n-1)}{2} \in Î˜(n^2) \)
- Also: \( f(n) \in O(n^2) \) â€” but **not** just \( O(n) \)

So:

âœ… It's **O(nÂ²)** â€” upper bound  
âœ… It's **Î˜(nÂ²)** â€” because that's exactly how it grows  
âŒ Not **O(n)** â€” that would be a lie

---
